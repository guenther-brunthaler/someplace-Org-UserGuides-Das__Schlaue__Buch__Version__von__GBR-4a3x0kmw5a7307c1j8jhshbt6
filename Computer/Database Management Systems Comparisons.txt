MySQL (2010):
http://sql-info.de/mysql/gotchas.html
In C geschriebenes RDBMS.
Galt einst als "sauschnell" und war irrsinnig beliebt bei mietbaren Webservern, wo typischerweise MySQL als DB und PHP als Programmiersprache verfügbar waren. Die Welt hat sich seit damals aber weitergedreht, und heute sind andere Implementierungen wie SQLite3 deutlich schneller als MySQL, während andere wie PostgreSQL deutlich mehr können. MySQL ist irgendwie zwischen den Stühlen und eigentlich braucht es kein Mensch mehr. Es zehrt daher im wesentlichen von seiner ehemaligen weiten Verbreitung, und ist immer noch häufig anzutreffen obwohl es bei weitem nicht mehr die Bedeutung hat wie einst. Ein weiteres Problem vom MySQL könnte der Umstand sein, dass es nun von ORACLE übernommen wurde und gewisse Zweifel herrschen, wie interessiert ein Datenbankhersteller wie ORACLE daran sein kann dass MySQL statt der kostenpflichtigen ORACLE-DB eingesetzt wird.

MariaDB (2020):
Ein Fork von MySQL dessen Entwicklung nicht von ORACLE sondern einer OpenSource-Entwicklergruppe (oder war es nur eine andere, allerdings OpenSource-basierte Firma?) koordiniert wird. Seit dem Fork kamen bei beiden Datenbanken zusätzliche Features hinzu, aber im großen und Ganzen scheint MariaDB immer noch im wesentlichen ein Ersatz für MySQL zu sein. Es wird auch ständig beliebter; viele Projekte favoritisieren inzwischen MariaDB gegenüber MySQL. Gleichwohl ist es nicht völlig identisch zu MySQL und es dürfte wohl Fälle geben wo man die eine der beiden Datenbanken nicht so ohne weiteres durch die andere ersetzen kann. Das Gegenteil trifft allerdings wesentlich häufiger zu.

Firebird (2020-07-12):
Eine sehr vollständige, klassische SQL-DB mit sehr geringem Hauptspeicherverbrauch. Unter NT4 brauchte das Ding (allerdings die Version von vor Jahrzehnten) keine 2 MB Hauptspeicher im inaktiven Betrieb (Dienst läuft aber keine Aktivität). Im Gegensatz zu den meisten anderen OpenSource-DBs war hier schon immer der komplette SQL-Standard (allerdings ein älterer) bis auf minimalste Unterschiede implementiert; sowohl alle Spielarten von JOINs als auch Stored Procedures oder Trigger waren voll implementiert. Firebird ist der OpenSource-Fork des Borland Interbase Servers, und *sehr* stabil und ausgereift. Allerdings wirkt er nach heutigen Maßstäben schon etwas angestaubt; R-Trees, Hashes oder Volltextsuche sucht man dort vergebens (wenn mich mein Gedächtnis nicht trügt; ist schon ein paar Jahre her dass ich das Ding installiert hatte). Wenn einem allerdings klassische SQL-Features reichen, ist Firebird eine ausgezeichnete und jahrelang ausgereifte, stabile Lösung. In Firebird 3 sind sowohl Integer-Typen fester Länge (bis 64 Bit) als auch Floating-Point-Typen und Dezimal-Datentypen ebenso wie BLOBs (bis zu 4 GiB Größe) und Text-Typen (auch UNICODE-tauglich, jedoch nur bis 32 KiB Speicherbedarf) verfügbar. Mehrdimensionale Arrays sind ebenfalls innerhalb von Datenfeldern möglich. Zahlen scheinen leider mit fixer Länge gespeichert zu werden, so dass es ineffizient sein dürfte wenn Datenfelder welche größe Werte erlauben tatsächlich nur sehr kleine Werte speichern. Recursive Common Table Expressions werden unterstützt. Diese sind schneller und speicherplatzeffizienter als wenn man dasselbe mittels Schleifen in den ebenfalls verfügbaren PSQL Procedural Language Extensions implementiert. Wenn BLOB-E/A nicht mit API-spezifischen Funktionen sondern wie mit normalen SQL-Strings durchgeführt wird (was erlaubt ist), werden sie auch genau wie SQL-Strings behandelt und sind dann daher ebenfalls auf 32 KiB Größe begrenzt. Firebird kann benutzerdefinierte externe Funktionen (UDFs) aus Shared Libraries in den Server laden welche dann in SQL zur Verfügung stehen. Es gibt keine benutzerdefinierten Datentypen oder gar solche Index-Typen. Allerdings kann eine UDF natürlich beliebige intern verwendete benutzerdefinierte Datentypen als Binärstring serialisieren bzw. deserialisieren welcher dann im Datensatz abgespeichert wird. Ein großes Problem älterer Firebird-Versionen war die Dokumentation, die nur in Form von veralteten PDF-Dokumenten mit Ergänzungen als neuere nicht-PDF-Dokumente verfügbar war. Dadurch war es praktisch unbenutzbar für Gelegenheits-Benutzer. Zumindest ab 2020 ist dieses Problem aber gelöst; es gibt nun eine sehr schöne Dokumentation in einer einzigen HTML-Seite für Firebird. (Weitere Formate wie PDF sind verfügbar.) Einschränkung des soeben geschriebenen: Momentan (2020-07-12) gibt es eine vollständige Dokumentation nur für die ältere Version 2.5, für die neue Version 3 gibt es (wie schon früher) keine vollständige Dokumentation, so dass man sich alles mühsam aus verschiedenen Einzeldokumenten zusammensuchen muss. Ich hoffe jedoch, dies wird sich bald ändern. Firebird kann auch UUIDs erzeugen welche einfach als binäre 16-Byte Zeichenketten (zugeordneter Zeichensatz "BINARY") gespeichert werden. Zur Ein-/Ausgabe gibt es aber Konvertierungs-Funktionen, welche UUIDs in eine der üblichen Hex-Darstellungen für GUIDs umwandeln. Firebird nutzt seit je her MVCC, wodurch (zumindest im ISOLATION LEVEL SNAPSHOT) weder Lese- noch Schreiboperationen jemals blockiert zu werden brauchen. Ein Nachteil ist aber erhöhter Speicherbedarf für das Abspeichern der verschiedenen Versionen desselben Datensatzes, was später zur Laufzeit eine Art Garbage-Collection erfordert wenn man den Speicherplatz für nicht mehr verwendete Versionen von Datensätzen wieder frei geben möchte. Fazit: Eine Firebird-Installation ist kompakt und ressourcenschonend, beherrscht aber keine (effiziente) Volltextsuche und die erzeugten Datenbanken dürften um einiges mehr Platz belegen als für SQLite3. (Was aber freilich erst bei sehr großen Datenbanken relevant werden wird.) Dafür unterstützen Firebird-Datenbanken besonders gut das komplette Ablegen der (Daten-) Verarbeitungslogik einer Applikation innerhalb der Datenbank in Form von Stored Procedures, Views und Triggers.

Berkeley-DB (2012):
In C geschriebene Non-SQL-DB.
Im Grunde handelt es sich dabei um kein eigenständiges Programm, sondern nur um eine Library welche einfache, elementare Datenbankfunktionen für beliebige Applikationen zur Verfügung stellt.
Diese Funktionen folgen typischerweise immer dem Schema "Schlüssel-Wert": Man kann ein Schlüssel-Wert-Paar speichern, oder den Wert zu einem gegenenen Schlüssel suchen, den Wert ersetzen, oder das Paar löschen.
Die verschiedenen Funktionsgruppen in BerkeleyDB unterscheiden sich dabei im wesentlichen nur darin wie die entsprechenden Zuordungen zwischen Schlüsseln und Werten implementiert sind. Was es in BerkeleyDB nicht gibt, sind "TABLES" im Sinne von SQL, wo beliebig viele "Spalten" in einer Tabelle enthalten sein können. Es gibt in jeder BerkeleyDB-Datei immer nur 2 Spalten: Eine enthält den Schlüssel, die andere den Wert. Allerdings kann man beliebig viele solcher Dateien anlegen, so dass dies kein grundsätzliches Problem ist.
Was aber sehr wohl problematisch ist, ist dass es in BerkeleyDB keine komplexeren Queries als elementare Schlüsselabfragen und auch keine JOINs gibt. All diese Dinge, welche in einer SQL-DB der Query Optimizer implementiert, muss man hier selbst machen bzw. aus elementaren Operationen zusammensetzen. Eine SQL-DB tut das intern ebenfalls, aber die Umsetzung erfolgt automatisch und man muss sich um keine Details kümmern.
BerkeleyDB ist daher für wirklich komplexe DB-Abfragen denkbar ungeeignet. Viele Applikationen brauchen dies aber gar nicht, und dann reicht BerkeleyDB vollkommen aus.
Pro "Datenbank" (würde in einer SQL-DB nur einer Tabelle entsprechen) kann man zwischen 4 Typen von Zugriffsmethoden wählen: B-Tree, Hash, Queue und Recno. Recno verwendet einen Integer als Schlüssel und speichert Daten in der Schlüsselreihenfolge. Queue tut dasselbe, vergibt die Schlüssel aber selbst und stellt ein typisches "Queue"-API zur Verfügung, wo man Daten an einem "Ende" der Queue anhängt und am anderen wieder entfernt. Queue ist im Gegensatz zu allen anderen Zugriffsmethoden auf fixe Datensatzlängen beschränkt, erlaubt dafür aber auch als einziges Record-Level-Locking. Alle anderen Methoden basieren auf Page locking.
BerkeleyDB unterstützt Write-Ahead-Logging und Transaktionen sowie Replikation von einem Master auf eine beliebige Menge Slaves. Transaction Logs können optional auch als Dateien gespeichert werden, wodurch sich eine DB wie eine "Zeitmaschine" verwenden lässt - allerdings mit sequentiellem Zugriff auf die Zeitachse. (Sprich: Möglich, aber teuer und langsam, und nur für Notfall-"Restore"-Operationen sinnvoll zu gebrauchen.)
BerkeleyDB hat auch eine sehr breite Installationsbasis und wird von einer Unzahl von Programmen für irgendwelche Kleinigkeiten verwendet.
Ein Problem von BerkeleyDB könnte allerdings die Lizenz sein - die DB wird von Oracle entwickelt - und die zwar problemlos für reine OpenSource-Projekte ist, für kommerzielle oder nur teilweise OpenSource-Projekte aber unter Umständen hinderlich sein könnte.

PostgreSQL (2010):
http://sql-info.de/postgresql/postgres-gotchas.html
In C geschriebenes RDBMS.
Gilt als das umfangreichste und leistungsstärkste OpenSource RDBMS.
Allerdings legt es jedes DB-Objekt in einer separaten physischen Datei ab, was durch die Clusterung auf Dateisystem-Ebene platzmäßige Nachteile bei sehr vielen Tabellen mir sehr wenig Inhalt bedeuten kann. Diese Nachteile werden aber irrelevant je größer die einzelnen Tabellen werden. Und bei großen Datenmengen scheint PostgreSQL besser zu skalieren als alle anderen OpenSource-DBs.
PostgreSQL bietet vor allem aber auch die mit Abstand meisten Features aller OpenSource-DBs.
Es erlaubt eine Vielzahl an Sprachen mit denen man Prozeduralen Code in die DB einbinden kann, wie TCL, Perl und einige mehr; daneben hat es auch eine "eigene" prozedurale Sprache die in der Syntax an SQL angelehnt ist.
PostgreSQL hat auch ein erweiterbares Index-System, so dass man jederzeit benutzerdefinierte Index-Implementationen als DLL hinzu laden kann.
Es verfügt über eine integrierte Volltext-Indexmaschine, aber auch spezielle R-Tree-basierte Indizes für geografische Daten. Normale Indizes sind als B-Trees implementiert.
Die DB erlaubt es des weiteren, beliebige benutzerdefinierte Datentypen als DLL zu implementieren, die dann in den DB-Server geladen werden. Die DLL muss dabei ein paar Operationen zur Verfügung stellen mit denen die DB die Datentypen manipulieren, eingeben oder ausgeben kann; davon abgesehen können sie aber intern eine beliebig komplexe Struktur haben.
Weiters unterstützt die DB objektorientierte Erweiterungen von SQL, mit denen sich (einfache) Vererbung zwischen Tabellen realisieren lässt.

Derby (2010):
Rein in JAVA geschriebenes RDBMS.
Sehr langsam; H2 ist viel schneller.

H2 (2023):
Rein in JAVA geschriebenes RDBMS.
Hat einen Webserver eingebaut, so dass man die DB über einen Browser administrieren kann. Soll sehr beliebt sein. H2 unterstützt eine Teilmenge des SQL-Standards und beherrscht unter anderem referenzielle Integrität, Transaktionen, Clustering, Datenkompression (LZF, DEFLATE), Verschlüsselung (AES-128-CBC, XXTEA) und SSL. Anders als die Verschlüsselung scheinen die Komprimierungsfunktionen nur als SQL-Funktionen zur Verfügung zu stehen, welche um Nutzen zu entfalten in Abfragen aktiv verwendet werden. Eine Volltextsuche ist (anders als bei HSQLDB) implementiert. Im Debian Paketbaum verfügbar. Ca. 2 MB Download-Umfang. Auch hier muss man sich die Dokumentation selber herunterladen (als PDF 2 MB). (Unter Debian ist dafür nur ein API-Dokumentationspaket  verfügbar.) Basiert auf Maven, und installiert diverse XML Dateien von Maven mit. Hat Support zum Lesen und Schreiben von CSV-Dateien, allerdings ist das mehr zum Import/Export gedacht.,Viele Einschränkungen (keine Joins) und ist keine Konkurrenz für die CSV-Table-Features von HSQLDB. H2 kann genau wie HSQLDB wahlweise direkt in eine (JAVA-) Applikation eingebettet werden, oder als unabhängiger DB-Server gestartet werden.

HSQLDB (2020):
Rein in JAVA geschriebenes RDBMS.
Stellt die Basis für OpenOffice.org Base (zumindest zum Zeitpunkt von OOo 3.2) dar, und hat daher eine sehr hohe Installationsbasis. Die JAVA-affinen Leute ziehen aber meist H2 vor, wenn sie es sich aussuchen können. HSQLDB besteht im wesentlichen aus einer einzigen *.jar-Datei, in welcher sich folgende Funktionen aufrufen lassen: Datenbankserver, zugehöriger JDBC-Treiber, GUI-basierter Datenbankmanager ("Database Manager", sowohl eine AWT- als auch eine SWING-Version), grafisches Abfragewerkzeug (AWT-basiert), CLI-tool ("Sql Tool"), Transfer Tool (kann Datenbank-Schemas samt Daten zwischen JDBC-Datenquellen kopieren), Selbsttest-Utility. Ein besonderes Feature von HSQLDB ist es, CSV/DSV-Dateien direkt als externe Tabellen in die Datenbank einbinden zu können, und diese dabei nicht nur lesen sondern auch aktualisieren zu können. DSV-Dateien mit einer Kopfzeile werden unterstützt, jedoch wird diese lediglich ignoriert und bei Updates der Datei durch eine leere Zeile ersetzt. DSV-Tabellen haben ansonsten nur wenige Einschränkungen gegenüber "echten" Tabellen, wie sie benutzt werden können. Joins, Indizes und Trigger für DSV-Tabellen sind daher kein Problem. Freilich sollte man eine DSV-Datei nicht von außen verändern oder lesen, während sie vom Datenbankserver gerade benutzt wird. Kann auch Datenbanken auf Read-Only-Datenträgern (natürlich nur lesend) öffnen. Es gibt 3 Arten von Tabellentypen: Nur im Speicher gehalten, im Speicher gehalten und zusätzlich als SQL-Befehle serialisiert (werden beim Start ausgeführt um alles in den Speicher zu lesen), "cached" Tabellen (müssen beim Start nicht komplett in den Speicher geladen werden, Größe auf 8 TB beschränkt). Weiters kann man auch die ganze Datenbank als "Memory-Only" anlegen. Sie existiert dann nur temporär im RAM während sie geöffnet bleibt. HSQLDB ist primär dazu gedacht, mittels JDBC-Schnittstelle von JAVA-Programmen aus angesteuert zu werden. Es bringt jedoch auch ein eigenes Kommandozeilentool zur Administration und Datenmanipulation mit, so dass die meisten Funktionen auch von Scripten aus genutzt werden können. Tatsächlich ist dieses Tool aber eine Schnittstelle zum Zugriff auf eine beliebige Datenbank via JDBC, und kann daher grundsätzlich auch genutzt werden um auf andere JDBC-fähige Datenbanken zuzugreifen. Der Zugriff auf den Datenbankserver erfolgt über das Netzwerk (oder die Loopback-Schnittstelle) und kann optional über TLS verschlüsselt sein. Dazu werden die in JAVA integrierten Zertifikatsmöglichkeiten genutzt. Alternativ gibt es einen Standalone-Modus, wo der Datenbankserver im selben Prozess wie die ihn benutzende Applikation läuft. HSQLB bietet Users, Roles, Triggers, Transactions, Sequences, Auto-increment columns, BLOBS und Dezimaldatentypen. Zu fehlen scheinen Window-Funktionen und "WITH RECURSIVE" common table expressions. Transaktionen werden unterstützt, jedoch nur im schwachen Isolation-Level "Read Uncommitted" wo andere Transaktionen bereits Änderungen sehen können die noch nicht committed wurden. Etwas unklar ist der Support von Stored Procedures: Einerseits können separat kompilierte JAVA-Funktionen (vermutlich im CLASSPATH) als Stored Procedures deklariert und benutzt werden. Andererseits ist eine proprietäre Scriptsprache namens "PL" eingebaut, jedoch wird auch von PL/SQL in der Anleitung erwähnt. Bei "PL" ist weiters unklar ob dieses nur im CLI-Tool verfügbar ist, oder auch über JDBC benutzbar ist. Bei PL/SQL ist nicht klar ob dies überhaupt in HSQLDB selbst eingebaut wird, oder nur über JDBC-Verbindungen zu externen Datenbanken genutzt werden kann welche ihrerseits PL/SQL unterstützen. Zumindest grundlegende Stored Procecures wie CASEWHEN(), CASE(), IFNULL(), CAST() und SUBSTRING() sind aber fix eingebaut und können auf jeden Fall benutzt werden. Die RAM-Effizienz von HSQLDB ist leider eher gering: Bereits jede Zeile einer Tabelle die nur eine einziges INTEGER-Spalte enthält kostet mindestens 80 Byte RAM durch den Grundaufwand. Nicht-variabel lange Datentypen in Spalten werden überdies unkomprimiert mit fixer Länge abgespeichert, und jede zusätzliche Spalte verursacht noch zusätzlichen Metadatenoverhead pro Zeile. HSQLDB wurde vom selben Entwickler wie H2 gestartet. Doch seit dieser sich nur noch um H2 kümmert, haben andere Development die Weiterentwicklung übernommen. Ebenfalls im Debian-Paketbaum vorhanden (Dokumentation muss man sich allerdings separat besorgen, 2 MB entpackt). Nur 1 MB Installationsumfang. Zudem meist vorinstalliert, da LibreOffice Base es (Stand 2023) ebenfalls verwendet.

Sqlite3 (2010):
In C geschriebenes RDBMS.
Gilt als sehr schnell und kann auch ohne Server direkt in Applikationen eingebettet werden. Dabei kann die Applikation dann auch SQL um zusätzliche Funktionen, COLLATING SEQUENCEs etc. erweitern.
Ein Standalone-CLI ist verfügbar, mit der man alle Befehle auch direkt aus der Konsole ausprobieren kann.
Seit geraumer Zeit bringt SQLite3 standardmäßig auch Erweiterungen mit, mir denen R-Trees (für mehrdimensionale Bereichsabfragen, wichtig für GIS-Anwendungen, könnte aber auch zur Verwaltung von freien und belegten Zeitabschnitten genutzt werden, etwa in einem Kalenderprogramm) und Volltextindizierung (sowie natürlich Volltextsuche) möglich sind.
Eine Datenbank befindet sich immer in einer einzigen physischen Datei, welche (glaube ich) plattformneutral ist.
Eine Spezialität von SQLite ist der Umstand, dass es keinen Zwang gibt bestimmte Typen in die COLUMNs einer TABLE zu schreiben. Zwar erzeugt ein CREATE TABLE sogenannte "column affinities", aber das sind nur Defaults welche Feldtypen dort bevorzugt erwartet werden; kein Zwang. Eventuell werden Daten in Columns auch effizienter gespeichert wenn man die columns affinities beachtet. Aber es ist dennoch immer möglich, jeden Datentyp in jede Column zu schreiben.
Trotz des Umstandes dass eine Datenbank immer nur aus einer Datei besteht, lassen sich mehrere Datenbanken in eine Sitzung einbinden welche dann wie ähnlich wie TABLESPACEs verwendet werden können. Allerdings gibt es Einschränkungen bei solchen Cross-DB-Operationen, etwa was die referenzielle Integrität angeht.
SQLite gilt als sehr schnell, aber nach Berichten von Anwendern skaliert die Datenbank nur bis ein paar hundert MB (oder waren es GB?) gut. Sobald die DB größer wird, ist PostgreSQL schneller.
Das CLI von SQLite lässt sich bequem in Shell-Scripts einsetzen, da es ein einziges Executable ist und über Ein-/Ausgabeumleitung bequem mit Daten beschickt werden kann.
Applikationen in höheren Programmiersprachen sollten zur Kommunikation mit SQLite aber besser dessen natives API verwenden, das recht anwenderfreundlich gestrickt ist.
Allerdings unterstützt SQLite keinen verbreiteten Standard zur Kommunikation mit der Außenwelt, wie etwa ODBC oder JDBC.
Das wäre allerdings auch nur begrenzt hilfreich, da SQLite keinen Server besitzt sondern direkt in eine Applikation integriert wird bzw. als Commandline-Applikation aufgerufen wird. Und ODBC sowie JDBC dienen ja genau der Kommunikation mit einem externen Server, den es bei SQLite eben nicht gibt.
Beherrscht auch In-Memory-Datenbanken, d. h. kann komplett ohne Disk-Files auskommen.
Eine Spezialität von SQLite ist eine Installationsvariante, bei der es nur ein einziges .c und ein einziges .h File gibt in dem aller Code / Deklarationen enthalten sind. Dadurch ist es extrem einfach ein komplettes SQLite3 in die eigene Applikation einzubinden, ohne komplizierte Abhängigkeiten zwischen den verschiedenen Quelltextmodulen innerhalb von SQLite beachten zu müssen. Außerdem "sieht" der Optimizer des C-Compilers alles Bestandteile der Datenbank gleichzeitig, und kann so Inter-Prozedur-Optimierungen betreiben die unmöglich wären wenn er nur die einzelnen Funktionen getrennt übersetzen müsste.
Bei allem Lob hat SQLite3 hat aber auch Unzulänglichkeiten: Es hat keinen DECIMAL-Datentyp; alle Zahlen mit Nachkommastellen werden als Fließkommazahlen gespeichert. Das kann katastrophale Rundungsfehler zur Folge haben, die man bei Fließkommazahlen zwar gewohnt ist, die bei kommerziellen Applikationen aber komplett indiskutabel sind. Wenn etwa auf der Soll-Seite eines Kontos etwas abgezogen und auf der Habenseite hinzuaddiert wird, darf sich der Saldo nicht ändern. Bei Fließkomma-Arithmetik kann dies aber niemand garantieren. Ebenso fehlen spezielle Typen für Zeit und Datum. Man muss dies selbst als Text, UNIX Timestamps oder ähnliches speichern. Immerhin sind wenigstens dazu erforderliche Zeit- und Kalender-Umwandlungs-Funktionen eingebaut welche Abfragen nutzen können. Ein weiteres Problem sind die PRAGMA-Kommandos von SQLite3. Diese können zwar jede Menge nützlicher Parameter und Betriebsmodi einstellen; allerdings muss man sie bei jeder neuen Datenbankverbindung erneut einstellen sonst werden sie "vergessen". Besonders ärgerlich ist dies bei so grundsätzlichen Funktionen wie ob FOREIGN KEY Support aktiviert werden soll oder nicht. Oder das Secure-Delete Feature. Einmal vergessen, und man kann in Teufels Küche kommen. Konfigurationsfreiheit gut und schön, aber solche Settings gehören wirklich in die DB gespeichert! Was SQLite3 ferner nicht kann sind RIGHT OUTER JOINs und per-Statement Triggers. Updateable Views kann es auch nicht, aber das trifft ja leider auf die meisten freien RDBMS zu.
SQLite speichert die abgelegten Daten sehr kompakt, so dass die Datenbankdatei häufig kleiner ist als bei anderen Datenbanksystemen. Außerdem sind sie portabel zwischen verschiedenen Betriebssystemen. Angeblich sind SQLite-Datenbanken deswegen auch sehr beliebt als binäres Datenaustauschformat.

Drizzle (2010-09-09):
Ein Fork von MySQL. Danke schön; auf Wiedersehen!

CUBRID (2010-09-09):
Schlecht sieht es mit den unterstützten Zeichensätzen aus: Nur US-ASCII (angeblich auch Latin-1) und "Koreanisch" werden unterstützt; letzteres auch in UTF-8 Codierung. Da man mit UTF-8 alles speichern kann ist daher wohl eher die koreanische Sortierreihenfolge ein Problem wenn man Zeichen aus anderen Sprachen sortieren will. CUBRID beherrscht nur normale B-Tree-artige Indizes, weder R-Tree noch Full-Text-Search noch Hash. Keine Stored Procedures. Zumindest nicht in einer PL/SQL-ähnlichen Sprache - JAVA Stored Procedures sind möglich. Diese sind aber umständlich da sie separat kompiliert werden und auf dem DB-Server hinterlegt werden müssen. Erinnert verdächtig an HSQLDB! Von diesen Dingen abgesehen beherrscht CUBRID allerdings so ziemlich alles andere was man von einer SQL-DB erwartet. Es beherrscht auch vollen Trigger-Support, Partitioning (Value List, Range oder Hash) und sogar Replikation! Wird von der koreanischen Regierung gezielt gefördert und in großem Maßstab (zigtausende Server) verwendet. Es gibt nur eine Version davon, nicht wie sonst oft üblich eine abgespeckte Communitiy-Version und eine bessere aber teurere kommerzielle. Andererseits klingt CUBRID auch nach "schön brav, aber nichts besonderes". In dieser Hinsicht erinnert es sehr an Firebird - allerdings kann Firebird auch Stored Procedures. Interessant an Cubrid klingt jedenfalls das Replikations-Feature, das beherrschen andere OpenSource-SQL-DBs (außer PostgreSQL) nämlich so gut wie nie. Oder nur als kostenpflichtige Zusatzoption. Wenn man Daten replizieren können will aber dennoch die Fähigkeiten einer SQL-DB braucht, könnte CUBRID das richtige sein. CUBRID ist ferner stark auf HA ausgelegt - Heartbeat, Fail-Over etc. wird alles unterstützt. Allerdings ist es kein echtes verteiltes System - die Replikation erzeugt nur Read-Only-Kopien; writes hingegen wandern immer zuerst von der Slave- zur Master-DB. Wenigstens geschieht dies aber automatisch. Ein spezielles SQL-Extension von CUBRID ist für "Click Counts" gedacht, d. h. das "leichtgewichtige" Hochzählen eines Zählers in irgend einem Datensatz, ohne dass dafür schwergewichtige Locks oder Transaktionen gestartet werden müssen. In CUBRID kann ein Tabellenfeld auch Collection-Types enthalten, wie SET, MULTISET oder LIST. Das kann eigene Tables zu diesem Zweck und damit verbundene komplexe Locks beim Schreiben verhindern wenn man nur ein paar Einträge in einer Liste braucht und nicht gleich hunderte. Ein "composition" genanntes Feature in CUBRID erlaubt es, bei JOINs die OID von Tabelleneinträgen als Verknüpfungsfeld zu verwenden und dabei das eigentliche PRIMARY KEY Feld zu umgehen. Das kann mein langen oder mehrteiligen Primärschlüsseln Performance-Vorteile bringen. Was Backups angeht, arbeitet CUBRID ähnlich wie die "großen" bekannten DBs - man kann Snapshots ziehen, und alle Änderungen gegenüber diesen werden in Logs festgehalten die man ähnlich wie inkrementelle Backups archivieren kann. Dadurch kann man den Zustand der DB zu jedem Zeitpunkt exakt rekonstruieren bis zu dem die Logs zurück reichen, und nicht nur zum Zeitpunkt der einzelnen Snapshots bzw. Full-Backups selbst. Die Logs werden dabei nicht automatisch gelöscht; der Administrator kann daher durch einen entsprechenden cron-Job selbst bestimmen wie lange er die Logs aufbewahren will. Die Logs stellen daher in gewisser Weise eine Versionsverwaltung für die Datenbank dar. Allerdings muss man eine Kopie der Datenbank aus einem Snapshot erstellen und dann Logs "abspielen" um alte Versionen auslesen zu können; also vergleichsweise aufwändig. Es gibt ein umfangreiches grafisches Frontend für CUBRID; offenkundig alles in JAVA geschrieben. Auf CUBRID kann mittels JBDC, ASP, PHP, ODBC und C API zugegriffen werden. CUBRID unterstützt Updatable Views, allerdings mit zahlreichen Einschränkungen. BLOBs werden als BIT VARYING gespeichert; Maximallänge 1 Gibibit. Textfelder können bis 1 Gibibyte lang werden. Dezimalarithmetik bis 37 Stellen Genauigkeit und 64 Bit Integers werden unterstützt.

LucidDB (2010-09-09):
Ein "Column-Oriented" in JAVA und C++ geschriebenes System das speziell für Data-Warehousing konzipiert ist. Verwendet Bitmap-Indizes, und Multiversioning auf Page-Level. Das Aggregieren der Daten läuft über Hashing. Soweit ich das verstanden habe, werden Daten in LucidDB überhaupt nicht bearbeitet. Zwar kann man schon Tabellen erstellen, aber diese dienen nur zum Zwischenspeichern oder indizieren von aggregierten Ergebnissen, die aus bestehenden Tabellen abgeleitet wurden. Alle Daten werden nur aus anderen DBMS importiert, typischerweise via JBDC, und dann toll analysiert. Das Ding ersetzt daher aber keine Datenbank; es ergänzt sie nur um bessere Analysemöglichkeiten. Scheint daher in erster Linie für "Datewarehousing" gedacht zu sein.

MonetDB (2010-09-10):
Eine "Column-Oriented" Datenbank. Angeblich für komplexe Queries in großen Datenbanken geeignet. Klingt allerdings auch wieder nach "Data-Warehousing", genau wie bei LucidDB. Aber wenigstens ist es in C geschrieben; kein JAVA. Für Data Mining und OLAP konzipiert. MonetDB scheint ähnlich wie MongoDB primär eine In-Memory-DB zu sein. MonetDB beherrscht SQL, aber auch GIS-, XML- und Multimedia-Storage sowie XQuery-Abfragen zur Suche in XML-Dokumenten. Und im Gegensatz zu MongoDB beherrscht MonetDB auch Transaktionen, Logs, Snapshots, Hot-Backups und vollwertiges SQL. Die Dokumentation von MonetDB selbst meint, dass diese DB nicht für häufige Updates entworfen wurde; die Datenstrukturen sind für häufige und auch komplexe Queries ausgelegt. Im Gegensatz zu anderen, reinen OLAP-Datenbanken sind "kleine Updates" aber zumindest vollwertig möglich und sollten bei überschaubarem Volumen auch kein Problem sein. Wenn viele Anwender hingegen andauernd Daten ändern ist MonetDB nicht die beste Lösung. MonetDB ist zwar gut für SMP-Betrieb gerüstet, nicht jedoch für den Betrieb als echte verteilte DB. Unklar ist, ob MonetDB auch dynamisches SQL beherrscht. Es ist immer nur von einem "SQL Compiler" die Rede, und die native "Sprache" der DB ist nicht SQL sondern "MAL", die "MonetDB Assembly Language".

MongoDB (2010-09-09):
Eine nicht-SQL-DB, welche auf Map-Reduce aufbaut und Stärken im Clustering haben soll. Die eigentliche Logik erfolgt mittels JavaScript-Snippets, die direkt im Server als Teil des DB-Schemas gespeichert sind.
MongoDB ist für das Verwalten von dokumentorientierten Datenbanken gedacht, beherrscht Datentypen wie String, Integer, Real, UUID, Boolean, Datetime und BLOB; die intern aber alle als BSON-Objekte (binäre JSON-Variante mit Größenlimitierung auf 4 GB pro Datensatz) gespeichert werden.
Von Konzept her mag MongoDB interessant sein, aber 2 wesentliche Einschränkungen machen es derzeit (2010) für viele Einsatzgebiete unbrauchbar: Es hat nicht nur die oben durch BSON diktierte Beschränkung auf 4 GB pro Datensatz, sondern die ganze Datenbank darf nicht größer als 2 GB (zumindest im Falle von 32 Bit Betriebssystemen) sein! Allerdings gibt es ein von der eigentlichen DB separates GridFS, welches zum Speichern von BLOBs genutzt werden kann und keine grundsätzliche Größenlimitierung vorsieht. GridFS kann die BLOBs auch replizieren und verteilt speichern.
Weiters funktioniert MongoDB nur auf Little-Endian-Architekturen; offensichtlich hält man dort nicht viel von Serialisierung der Daten sondern schreibt die Daten raus wie sie im Speicher liegen.
Schließlich arbeitet MongoDB mit Datenbankdateien welche einfach mittels mmap() in den Speicher des Serverprozesses eingeblendet und dort in-memory modifiziert werden. Mit anderen Worten, die ganze E/A wird dem OS überlassen. Lediglich alle 60 Sekunden wird das File "geflushed" um in Falle eines Absturzes den entstandenen Schaden zu minimieren.
Da aber weder ein Rollback-Log noch ein Write-Ahead-Log verwendet werden - es gibt auch keinerlei Transaktionen - kann jeder Absturz des DB-Servers während des Zurückschreibens in die DB-Datei deren Inhalt potenziell korrumpieren.
MongoDB kennt auch keine Joins oder einen Query Optimizer im Sinne von SQL; es gibt nur einen recht statistisch arbeitenden Primitiv-Ersatz der einfach während der Ausführung der Queries periodisch verschiedene Varianten durchprobiert und dann bei der schnelleren bleibt.
Wie man ohne Transaktionen, Referenzielle Integrität und Joins atomare oder zumindest konsistente Änderungen an der DB durchführen soll, scheint ein Problem zu sein das der Anwendungsprogrammierer jedesmal selbst zu lösen hat (durch Locks etwa).
Grundsätzlich macht MongoDB den Eindruck, als so eine Art "kleines GoogleFS" konzipiert zu sein: Nur wenige die streng miteinander koordiniert schreiben, und viele die lesen. Und die zu lesenden Daten werden weithin verteilt und repliziert. Dazu gibt es in MongoDB "Shards", die sehr ans GoogleFS angelehnt zu sein scheinen.

SmallSQL (2010-09-09):
Eine Pure-JAVA DB mit SQL-92 und SQL-99 Unterstützung und JBDC-3.0 Driver. Nur ein paar 100 KB Installationsumfang. Setup-Free. Klingt irgendwie exakt nach einer Art JAVA-Gegenstück zu SQLite3. Nur dass letzteres bekannter und weiter verbreitet ist. Allerdings ändert sich das Bild sobald man erfährt, dass SmallSQL weder den kompletten SQL-92 noch den SQL-99 Standard beherrscht, sondern nur ein winziges Subset davon! Konkret kann es gerade mal das grundlegende SELECT, INSERT, DELETE, UPDATE und damit hat es sich. Keine Trigger, keine stored Procedures, ja nicht einmal Transaktionen, Joins, Indizes oder referentielle Integrität scheint es zu kennen! Nicht einmal ob es ein PRIMARY KEY AUTOINCREMENT kennt bin ich sicher. Auf jeden Fall ist das ganze so minimal dass es schon geradezu lächerlich ist.

XBSDB (2010-09-09):
XBSDB steht für "Cross-Browser JavaScript Database library" und ist eine minimal-Implementation von SQL ähnlich wie SmallSQL. Eigentlich ist es überhaupt kein SQL, sondern nur ein Haufen JavaScript-Funktionen mit denselben Namen wie SQL-Statements und ähnlichen Argumenten. Die Daten selbst liegen in JavaScript-Arrays bzw. Hashes vor - XBSDB ist also nur ein Front-End, um mit den in JavaScript vorhandenen Hashes ein wenig komfortabler arbeiten zu können. So etwas wie Joins oder gar Transaktionen kennt es auch nicht; aber wenigstens kann es die grundlegenden anderen Funktionen eines SELECT. Und im Gegensatz zu SmallSQL kann man wenigstens auch Indizes definieren. Wenn man in einer Web 2.0 Applikation im Client-Browser ein bisschen origineller sortierte oder gruppierte Daten anzeigen will, ist XBSDB sicher weniger Aufwand als alles selber "mit der Hand" zu machen. Die ganze Datenbank, aber auch individuelle Tabellen, kann in JSON-Objekte gedumpt oder wieder daraus gelesen werden. SELECT gibt immer alle Treffer direkt in einem Array zurück; es gibt aber auch CURSOR-ähnliche Varianten welche nicht alle Daten sondern nur ein Array mit deren Schlüsseln zurück geben. Auf jeden Fall ist das ganze offensichtlich nur für *überschaubare* Datenmengen geeignet.

Virtuoso Universal Server (2010-09-09):
Ein Hybrid, der die Funktionalität eines traditionellen RDBMS, ORDBMS, RDF, XML, Textdokument-Speichers, Web application Servers and File servers in einem einzelnen System vereinigt. Triple-Store mit SPARQL; auch geclustert. Volltextsuche. Skaliert bis 32 TB (8 KB DB-pages mit 32 Bit Indizes). Toll und super; scheint aber für Replikation nicht besonders geeignet zu sein. Es gibt eine OpenSource-Version als auch eine kommerzielle Version. Man kann sich ausmalen, was das für die Lizenz bedeutet: GPL statt LGPL und für kommerzielle Projekte daher ungeeignet - es sei denn man ist bereit zu zahlen. Virtuoso verwendet zur internen Kommunikation zwischen Client und Server SOAP und andere textlastige Protokolle - das bedeuted aufwändiges Parsen und entsprechend einen geringeren zu erwartenden Throughput.

ndbm (2010-09-30):
Eine Gruppe primitivster Funktionen zur Verwaltung einer Hash-Tabelle in einer Datei, die Bestandteil des POSIX 1003.1-2008 Standards ist. Beliebige Bytestrings können sowohl als Schlüssel als auch als Wert dienen. Ein ineffizientes Interface, da keine Kollisionsbehandlung enthalten ist: Wenn zwei unterschiedliche Schlüssel/Wert-Paare geschrieben werden deren Schlüssel auf denselben Wert hashen, überschreibt das 2. Paar das erste. Man muss daher, um sicher zu gehen, erst den gefundenen Eintrag lesen, die Schlüssel vergleichen, und weiß erst danach ob es sich um eine Hash-Kollision oder das Update eines bereits vorhandenen Datensatzes handelt. Im Fall einer Hash-Kollision muss man sich zudem selbst darum kümmern diese irgendwie aufzulösen. Es gibt zwar erweiterte Versionen von ndbm welche dieses Manko nicht haben; diese sind jedoch nicht Teil des Standards. Der wahre Wert von ndbm besteht primär in seiner Rolle als Modell-API für zahlreiche ähnliche Libraries, welche dieselbe Funktionalität bieten ohne aber dieselben Schwächen zu haben, und darüber hinaus zusätzliche Funktionen bieten. gdbm oder Berkeley-DB sind Beispiele dafür. Solche erweiterten Libraries bieten fast immer einen aufrufkompatiblen Kompatibilitätsmodus für ndbm; in den meisten Fällen freilich ohne die schwachsinnige (oder wohl eher fehlende) Kollisionsbehandlung des Originals.

CouchDB (2011-07-29):
Das in Erlang geschriebene CouchDB gehört zur Gruppe der NoSQL-Datenbanken. Es ist spezialisiert auf die Verarbeitung von Dokumenten, die beliebig strukturiert sein können. Als Austauschformat fungiert JSON. Meine Meinung: Erlang? - Unbrauchbar!

Cassandra (2011-10-19):
Apache Cassandra ist eine in JAVA geschriebene verteilte NoSQL-Datenbank für große Datenmengen (eine Datenbank mit 100 TB auf 150 Nodes ist bereits im Produktionsbetrieb). Im Gegensatz zu vielen anderen ähnlichen Systemen sind hier alle Nodes gleichwertig; es gibt also keine Master-Slave-Beziehungen, und man kann eine Datenbank auch mit einem einzigen Server betreiben ohne zusätzliche Koordinations-Server zu benötigen. Dadurch hat das System beim Einsatz in einem Cluster keinen Single Point Of Failure. Normalerweise werden die Daten schlüsselbezogen zwischen den verschiedenen Nodes aufgeteilt; Replikation zur Fehlertoleranz wird aber auch unterstützt. Millionen Reihen als auch Spalten sind kein Problem. Range-Queries und Abfragen die viele Zeilen liefern sind jedoch langsam und benötigen viel RAM. Die Anzahl der Spalten im Ergebnis ist hingegen belanglos. Die kleinste Dateneinheit in Cassandra ist eine Column, die einen binären Namen, binären Inhalt und einen 64-bit-Timestamp hat. Der Timestamp wird zur Konfliktauflösung bei der Replikation verwendet; was genau er angibt ist egal solange größere Zahlen spätere Zeit ausdrücken. Für Namen und String-Inhalte wird normalerweise UTF-8 verwendet, für Timestamps Mikrosekunden seit der UNIX Epoch. Die Nodes in einem Cluster sollten NTP zur Zeitsynchronisation verwenden. Spalten werden in "Column Families" zusammengefasst, das entspricht sozusagen Tabellen in SQL. Allerdings mit dem Unterschied dass jede Spalte in der Tabelle optional ist und auch keinen Platz belegt wenn es nicht verwendet wird. Leider erfordert jedwede Änderung an diesen Families einen Neustart des DB-Servers (aller Nodes). Jede Column-Family wird in einem separaten File gespeichert. Ein "Datensatz" in Cassandra besteht aus einem "Row Key" der bestimmt auf welchem Node der Datensatz gespeichert wird, und innerhalb dieses Nodes verbindet derselbe Row Key beliebig viele Spalten, wobei jede einzelne Spalte einer bestimmten definierten Column Family zugeordnet sein muss und jede Column Family auch nur maximal einmal im Datensatz vorkommen darf. Ein Sonderfall sind "Super Columns", das sind Columns die als Wert dasselbe wie eine Row enthalten können (allerdings mit demselben Row-Key assoziert). Das ganze ist allerdings nicht rekursiv; Super-Columns dürfen nicht wiederum Super-Columns enthalten. Eine maximal 2-stufige Hierarchie daher. Column Families werden zu Keyspaces zusammen gefasst, damit ergeben sind sozusagen logisch separate Datenbank-Instanzen. Jede verteilte Cassandra-Instanz kann mehrere solche Keyspaces hosten. Cassandra kann Range-Queries auf Schlüsselbereiche anwenden, doch das funktioniert nur effizient wenn die Aufteilung der Rows auf Nodes so vorgenommen wurde, dass jeder Node aufsteigende Schlüsselwerte speichert statt die Rows gehashed auf die Nodes zu verteilen. Cassandra erzeugt keine Indizes "on the fly", daher muss die Struktur der DB besser im Vorhinein geplant werden. Es wird auch Denormalisierung der Daten empfohlen solange der Mehrbedarf an Platz dafür nicht all zu sehr ausartet, da die Daten in der selben Instanz einer Column Family physisch zusammenhängend gespeichert werden. Die Speicherplatzeffizienz von Cassandra ist mir etwas unklar; so werden häufig JSON-Daten zur Erklärung des Datenbankaufbaus verwendet, doch es ist nicht ersichtlich ob Cassandra die Daten intern auch im (ineffizienten) JSON-Format speichert, oder ob dies nur der Illustration dient. Ich hoffe einmal letzteres. Die Konsistenzgarantien von Cassandra sind nicht berauschend: Je nach Konfiguration (Maß der Replikation) sehen Reader entweder das zeitlich zuletzt erfolgte Write eines bestimmten Records, oder sie sehen für kurze Zeit (Millisekunden aber es kann vorkommen) eine veraltete Version davon. Von referenzieller Integrität kann man hier also nur träumen, und diese "Garantie" ist wohl auch der Grund dafür dass Denormalisierung (also wenn möglich alles zusammengehörige im selben Datensatz zu speichern) empfohlen wird. Immerhin scheinen wenigstens die einzelnen Reads und Writes atomar zu sein.

Hadoop (2011-10-28):
Hadoop ist eine von der Apache Foundation geflegte und dem Google Filesystem bzw. Google MapReduce nachempfundene JAVA-Implementation einer verteilten NoSQL-Datenbank. Im Gegensatz zu Cassandra ist es kein P2P-System sondern verschiedene Server-Typen im Cluster übernehmen unterschiedliche administrative Aufgaben. Ähnlich wie bei Googles BigTable und MongoDB bringt Hadoop auch sein eigenes verteiltes Dateisystem als Grundlage der Datenbank mit, HDFS genannt. Neben diesem unterstützt es aber auch alternative Backends zur Datenspeicherung, wie Amazon S3, CloudStore und ähnliche Dienste weiterer großer Anbieter, aber auch simple FTP- Server und HTTP-Server (für Readonly-Zugriff). All dies macht Hadoop zu einem Liebkind vieler kommerzieller Anbieter welche Zusatzprodukte- oder Dienste dafür anbieten; einige haben auch modifizierte proprietäre Versionen davon erstellt. Entsprechend ist man mit Hadoop gut versorgt wenn es einem um kostenpflichtige kommerzielle Services geht, und von den Skalierungsmöglichkeiten her ist die Datenbank auch kaum begrenzt. Nachteil gegenüber Cassandra ist das komplexere Setup sowie der Umstand dass man mehr als einen Node zum Betrieb braucht. Außerdem fließen teilweise Details aus der Netzwerk-Infrastruktur in die Konfiguration ein, etwa welche Router es gibt usw. Bei Cassandra hingegen kann der Cluster auch nur aus einem einzigen Node bestehen, und zur Kommunikation zwischen den Nodes reicht grundsätzlich die Kenntnis der IP-Adressen bzw. DNS-Names. Hadoop ist daher offensichtlich eher für Rieseninstallationen vorgesehen, während Cassandra klein beginnen und dann skalieren kann. Dafür fehlt Cassandra der vielseitige Backend-Support - es ist dafür gedacht es auf Servern als verteilte Applikation unter eigener Kontrolle laufen zu lassen. Wenn man vorhat die Datenbank zunächst selbst zu hosten aber früher oder später auf S3 und ähnliche kommerzielle "Cloud"-Storage-Provider auszulagern, ist Hadoop daher eine sehr empfehlenswerte Wahl. Hadoop ist eigentlich ein Nebenprodukt bei der Entwicklung der verteilten Suchmaschine "Nutch", welche wiederum auf der Volltext-Suchmaschine "Lucene" basiert. Alle drei JAVA-basierten Projekte wurden auch vom selben Entwickler initiiert.

TDB (2011-12-25):
TDB ("Trivial DataBase") ist eine simple NoSQL-DB ähnlich wie DBM aber nicht kompatibel dazu. Schlüssel und Werte sind theoretisch beliebig lange (size_t) Byte-Strings; Schlüssel müssen eindeutig sein (hash-basiert).
TDB wurde als Teil des SAMBA-Pakets entwickelt und verwendet im Gegensatz zu SAMBA die LGPL3-Lizenz was auch den (unmodifizierten) Einsatz in kommerzieller ClosedSource-Software erlaubt. TDB verwaltet die User-Accounts in SAMBA und ist daher auf das Zugriffsmuster optimiert, dass die Datenbank nur kurz geöffnet und wenige Operationen durchgeführt werden; dafür können aber viele Prozesse gleichzeitig und dabei auch schreibend auf die DB zugreifen ohne dass es zu Problemen kommt. Der Dateimanager "Thunar" verwendet TDB um per-Datei-Metadaten (die "Emblems") zentral abzuspeichern und für Directory-Listings abzufragen. Entsprechend unterstützt TDB optional File Locking und Transaktionen. Letztere können sogar geschachtelt werden. Einzelne Transaktionen sind voll von einander isoliert (sehen unterschiedliche Sichten der Datenbank; durch Rollback-Logs implementiert). Transaktionen werden nicht für In-Memory-DBs unterstützt. Nicht benötigte Features (etwa verschachtelte Transaktionen) können beim Öffnen der DB deaktiviert werden was dann falls kein zugreifender Prozess das Feature anfordert zu den Runtime-Overhead verringert. Einige Features (memory mapping und file locking) können überdies beim Compilieren permanent deaktiviert werden. TDB cached generell nichts (zumindest nichts was über das Caching des Betriebssystems/Dateisystems selbst hinaus ginge). Dadurch gibt es auch keine expliziten Synchronisations/Flush Funktionen. Es gibt Spezialfeatures um einen Sequenzzähler pro Datenbank erhöhen zu können oder den Inhalt einer Datenbank zu löschen wenn der zugreifende Prozess der einzige ist der die DB gerade geöffnet hat. Letzteres kann nützlich für DBs sein die nur der Koordination zwischen mehreren Prozessen dienen. Defaultmäßig wird die Hashfunktion von Bob Jenkins verwendet die einen 32-Bit-Wert liefert. Man kann aber auch eine eigene DB-globale Hash-Funktion angeben und die Hash-Größe ist beliebig aber konstant in jeder DB. Die Hash-Funktion dient dabei aber nur der Optimierung des Zugriffsverhaltens; Hash-Kollisionen sind nicht verboten. Die DB wird automatisch beim Schließen reorganisiert wenn das aus Effizienzgründen empfehlenswert ist. Das Paket ist ziemlich klein - 400 KiB für die Library inklusive Header file und Dokumentation. Eine kleine Einschränkung von TDB ist dass es auf der POSIX open()-Funktion aufbaut und nicht auf der ANSI-C Funktion fopen(). Des schränkt die Portabilität ein, auch wenn alle weit verbreiteten Systeme open() zumindest als Wrapper zur Verfügung stellen. Auf der anderen Seite bietet ANSI-C keine File Locking Funktionen und ist daher für den beabsichtigten Zweck ohnehin nicht alleinig ausreichend. TDB kann auch als in-memory DB betrieben werden. Soweit ich den Quelltext verstand, dürften die erzeugten DBs auch binär zwischen verschiedenen Plattformen austauschbar sein. Zwar werden die Daten plattformspezifisch optimal (endianness) abgespeichert, jedoch wird diese Information mitgespeichert so dass die Datensätze auch auf anderen Plattformen wieder korrekt geladen werden können.

LMDB (2014-06-09)
LMDB ("Lightning Memory-Mapped Database Manager"), bezeichnet sich selbst allerdings als "MDB", ist eine laut eigenen Benchmarks super-schnelle B-Tree basierte Datenbank mit vollständiger ACID-Semantik. Sie ist unter der wenig verbreiteten OpenLDAP-Lizenz veröffentlicht, die aber sehr liberal zu sein scheint, kurz ist und im wesentlichen alles erlaubt. Insbesondere ist eigene Modifikation erlaubt ohne diese veröffentlichen zu müssen. Ebenso spricht nichts gegen einen Einsatz in ClosedSource-Software. Die härteste Bedingung ist noch der Umstand, dass man eine 1:1 Kopie der Lizenzdatei jeder Art von Verteilung beilegen muss. Doch wie gesagt die ist nur kurz - ca. 1 Seite mit rund 10 Absätzen; einige davon nur 1 Zeile lang. LMDB wurde als Storage-Backend für irgend einen LDAP-Server entwickelt. Nur LevelDB ist in ein paar wenigen Benchmarks schneller; ansonsten sticht sie Konkurrenten wie SQLite3, BerkeleyDB, TokyoCabinet und eben meist auch LevelDB gnadenlos und grandios aus. Oftmals um den Faktor 10 und mehr. Sie ist auch ganz irrsinnig toll was Concurrency angeht, ist Multithreading-fähig und arbeitet mit mehreren Versionen von Datensätzen im Falle von Änderungen - Reader und Writer können einander nie behindern, und Writer können (dank automatischer Serialisierung) keine Deadlocks erleben. LMBD basiert auf memory-mapped Files, wobei diese aber nicht komplett in dem Speicher geladen werden müssen und daher der RAM-Bedarf gering ist. Allerdings beschränkt die Größe des virtuellen Adressraums die maximale Größe der Datenbank - entsprechend ist diese DB eher für 64-Bit-Systeme gedacht, da man bei 32 Bit Systemen maximal ein paar GB große Datenbanken betreiben kann. Realisiert wird das alles durch sequenzielles beschreiben freier Speicherseiten, so dass die Daten auch kompakt in der DB liegen. Hier sehe ich allerdings ein mögliches Problem: Speicherseiten scheinen erst dann wieder frei gegeben zu werden und für neue Schreiboperationen (am Anfang beginnend) zur Verfügung zu stehen, wenn sie *komplett* leer sind. Das könnte interne Fragmentierung bewirken, wo viele Speicherseiten existieren in denen nur ganz wenige Daten liegen die noch nicht gelöscht werden. Doch bevor auch diese letzten Daten gelöscht wurden, wird die Speicherseite nicht mehr für neue Schreiboperationen genutzt. Andererseits müsste man wohl in der Praxis testen wie schlimm dieser Effekt tatsächlich ist. Am geringsten ist er jedenfalls wenn man möglichst erst einmal alles hinzu fügt, und dann möglichst nur noch liest und eher wenige Änderungen macht, vom Hinzufügen neuer Datensätze abgesehen. Für Log-Files etwa ideal. Die ganzen tollen Multiversions-Features werden übrigens dadurch realisiert, dass bei Änderungen ein Copy-On-Write durchgeführt wird. Daher ändert sich am Original nichts wenn jemand dieses gerade lesen sollte; sobald niemand mehr darauf zugreift wird die alte Speicherseite wieder als frei gekennzeichnet. LMDB verwendet keinen eigenen Cache sondern verlässt sich auf das Caching des Filesystems. Der Code ist angeblich deutlich kleiner als der aller Konkurrenten - rund 32 KB auf amd64 was angeblich komplett in den CPU-Cache passt. Die Anleitung preist den Umstand dass LMBD weder eine Write-Ahead noch "Append-Only" (vielleicht WriteBack im ROLLBACK-Fall gemeint wie bei SQLite3) betreiben würde und daher viiiieeel schneller sei. Allerdings kann ich nicht so recht den Unteschied zwischen Copy-On-Write und Writeback-Transactions wie be SQite3 erkennen - scheint mir vom Konzept her irgendwie dasselbe zu sein. Das API scheint C-basiert zu sein, also kein C++ Zwang. Die Datensätze scheinen üblicherweise direkt als Pointer in die Memory-gemappte Datenbank zurück gegeben zu werden; das ist natürlich nett weil nichts durch die Gegend kopiert werden muss. Allerdings muss man die Daten natürlich selbst irgendwohin wegspeichern, bevor man eine DB-Operation ausführt welche das Memory-Mapping wieder ändert. Aber für schnelle Analyse-Schleifen über ausgewählte Datensätze ist es sicherlich optimal. Daten werden auch schön generisch als void* übergeben und Längen als size_t - keine komischen neu erfundenen Datentypen. Sehr nett. Man kann auch alle möglichen Flags beim Öffnen der DB angeben, um Dinge wie Read-Only, No-Sync, Lock-Settings etc. einzustellen. Die Datenbank ist "wartungslos" und "braucht" nicht kompaktiert zu werden; in wie fern dies auf die obige Gefahr der internen Fragmentierung bezogen ein Vorteil ist werden erst Praxistests zeigen. Ein lustiges Feature von LMDB scheint der Umstand zu sein, dass man auch Datenstrukturen die intern "verpointert" sind damit abspeichern kann. Dazu kann man eine Callback-Funktion festlegen, welche die enthaltenen Pointer reloziert wenn die LMDB den Datensatz an einer anderen Speicheradresse einzublenden beschließt als diese während des Schreibens des Datensatzes der Fall war. Insgesamt scheint LMDB einige Ähnlichkeiten zu TDB aufzuweisen mit dem wesentlichen Unterschied dass sie nicht Hash-basiert ist sondern sortierte Daten speichert. Beide Datebanken cachen nicht selbst sondern überlassen dies dem Dateisystem; bei TDB las ich allerdings nichts darüber dass es Memory-Mapped arbeitet - es sollte daher auch auf 32-Bit-Systemen große Datenbanken verwenden können. Möglicherweise arbeitet es auch platzeffizienter (wegen dem Fragmentierungsproblem von LMDB). Aber LMDB wird vermutlich schneller sein wenn viele Daten verarbeitet werden sollen. Bei nur wenigen durchzuführenden Operationen könnte TDB vielleicht schneller sein weil es auf dieses Zugriffsmuster optimiert wurde - aber auch das ist noch zu benchmarken.

CDB (2020):
Das ist eigentlich keine Datenbank, sondern nur die Beschreibung des Speicherformats einer solchen. Es gibt allerdings verschiedene Implementierungen von Datenbank-APIs, welche es erlauben mit Datenbanken in diesem Format umzugehen. Das Datenformat ist allerdings simpel genug, dass man es auch selbst ohne all zu großen Aufwand implementieren kann. CDB ist eine typische No-SQL DB, welche Schlüssel-Wert-Paare ablegen kann. "CDB" steht für "Constant Database", was auch den beabsichtigten Zweck offenbart: Dieses Datenformat ist dazu gedacht, dass ein einzelner Schreibprozess die ganze Datenbank während exklusivem Zugriff erzeugt, und danach wird sie dann nur noch vom beliebigen Prozessen gelesen. Daher sind auch keinerlei Locking-Mechanismen beim Zugriff erforderlich. Das CDB-Format spezifiziert im wesentlichen eine primitive 2-stufige Hash-Tabelle und zugehörige (simple) Hash-Funktion. Eine CDB kann maximal 4 GiB groß werden da alle intern verwendeten Indizes und Offsets nur 32 Bit groß sind. Schlüssel und Wert jedes Datensatzes sind Binärstrings variabler und beliebige Länge, soweit sich dies innerhalb der erwähnten Größenbeschränkung für die gesamte Datenbank ausgeht. Das CDB-Format ist verbreitet bei vielen Anwendungen, welche Nur-Lese-Daten für irgendwelche Zwecke im indiziertem Zugriff benötigen.
